{
	"cells": [
		{
			"cell_type": "code",
			"execution_count": 13,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Accuracy: 0.6442417331812998\n",
						"Classification Report:\n",
						"              precision    recall  f1-score   support\n",
						"\n",
						"           1       0.87      0.44      0.58       197\n",
						"           2       0.52      0.90      0.66       181\n",
						"           3       0.46      0.10      0.16       164\n",
						"           4       0.80      0.94      0.86       177\n",
						"           5       0.60      0.85      0.70       158\n",
						"\n",
						"    accuracy                           0.64       877\n",
						"   macro avg       0.65      0.64      0.59       877\n",
						"weighted avg       0.66      0.64      0.60       877\n",
						"\n"
					]
				}
			],
			"source": [
				"import pandas as pd\n",
				"from sklearn.model_selection import train_test_split\n",
				"from sklearn.naive_bayes import GaussianNB\n",
				"from sklearn.metrics import accuracy_score, classification_report\n",
				"\n",
				"# Load the data\n",
				"data = pd.read_csv('combined_metrics.csv') \n",
				"# Drop rows with missing values\n",
				"data.dropna(inplace=True)\n",
				"\n",
				"# Split the data into features (X) and target variable (y)\n",
				"X = data[['Mean_X', 'Std Dev_X', 'Energy_X', 'Entropy_X', 'Peaks_X']]\n",
				"y = data['category']\n",
				"\n",
				"\n",
				"# Split the data into training and testing sets\n",
				"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
				"\n",
				"# Initialize the Naive Bayes classifier\n",
				"nb_classifier = GaussianNB()\n",
				"\n",
				"# Train the classifier\n",
				"nb_classifier.fit(X_train, y_train)\n",
				"\n",
				"# Make predictions on the testing set\n",
				"y_pred = nb_classifier.predict(X_test)\n",
				"\n",
				"# Evaluate the performance of the classifier\n",
				"accuracy = accuracy_score(y_test, y_pred)\n",
				"print(\"Accuracy:\", accuracy)\n",
				"\n",
				"# Generate a classification report\n",
				"print(\"Classification Report:\")\n",
				"print(classification_report(y_test, y_pred))\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 22,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Best Hyperparameters: {'var_smoothing': 1e-09}\n",
						"Accuracy: 0.5883694412770809\n",
						"Classification Report:\n",
						"              precision    recall  f1-score   support\n",
						"\n",
						"           1       0.57      0.71      0.64       192\n",
						"           2       0.47      0.95      0.63       155\n",
						"           3       0.50      0.05      0.08       175\n",
						"           4       0.83      0.86      0.84       181\n",
						"           5       0.57      0.39      0.46       174\n",
						"\n",
						"    accuracy                           0.59       877\n",
						"   macro avg       0.59      0.59      0.53       877\n",
						"weighted avg       0.59      0.59      0.53       877\n",
						"\n"
					]
				}
			],
			"source": [
				"import pandas as pd\n",
				"from sklearn.model_selection import train_test_split, GridSearchCV\n",
				"from sklearn.naive_bayes import GaussianNB\n",
				"from sklearn.metrics import accuracy_score, classification_report\n",
				"\n",
				"# Load the data\n",
				"data = pd.read_csv('combined_metrics.csv')\n",
				"\n",
				"# Drop rows with missing values\n",
				"data.dropna(inplace=True)\n",
				"\n",
				"# Split the data into features (X) and target variable (y)\n",
				"X = data[['Mean_X', 'Std Dev_X', 'Energy_X', 'Entropy_X', 'Peaks_X']]\n",
				"y = data['category']\n",
				"\n",
				"# Split the data into training and testing sets\n",
				"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)\n",
				"\n",
				"# Initialize the Naive Bayes classifier\n",
				"nb_classifier = GaussianNB()\n",
				"\n",
				"# Define the hyperparameters grid to search\n",
				"param_grid = {\n",
				"    'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5]\n",
				"}\n",
				"\n",
				"# Initialize GridSearchCV\n",
				"grid_search = GridSearchCV(estimator=nb_classifier, param_grid=param_grid, cv=5, scoring='accuracy')\n",
				"\n",
				"# Perform GridSearchCV\n",
				"grid_search.fit(X_train, y_train)\n",
				"\n",
				"# Get the best hyperparameters\n",
				"best_params = grid_search.best_params_\n",
				"print(\"Best Hyperparameters:\", best_params)\n",
				"\n",
				"# Make predictions on the testing set using the best model\n",
				"best_model = grid_search.best_estimator_\n",
				"y_pred = best_model.predict(X_test)\n",
				"\n",
				"# Evaluate the performance of the best model\n",
				"accuracy = accuracy_score(y_test, y_pred)\n",
				"print(\"Accuracy:\", accuracy)\n",
				"\n",
				"# Generate a classification report for the best model\n",
				"print(\"Classification Report:\")\n",
				"print(classification_report(y_test, y_pred))\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 32,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Best Accuracy: 0.9840546697038725\n",
						"Best Test Size: 0.1\n",
						"Best Random State: 121\n"
					]
				}
			],
			"source": [
				"import pandas as pd\n",
				"from sklearn.model_selection import train_test_split\n",
				"from sklearn.naive_bayes import GaussianNB\n",
				"from sklearn.metrics import accuracy_score, classification_report\n",
				"\n",
				"# Load the data\n",
				"data = pd.read_csv('combined_metrics.csv')\n",
				"\n",
				"# Drop rows with missing values\n",
				"data.dropna(inplace=True)\n",
				"\n",
				"# Split the data into features (X) and target variable (y)\n",
				"X = data[::-1]\n",
				"y = data['category']\n",
				"\n",
				"# Define the range of test sizes and random states to iterate over\n",
				"test_sizes = [0.1, 0.15, 0.2, 0.25, 0.3]\n",
				"random_states = list(range(42, 201))\n",
				"\n",
				"best_accuracy = 0\n",
				"best_test_size = 0\n",
				"best_random_state = 0\n",
				"\n",
				"for test_size in test_sizes:\n",
				"    for random_state in random_states:\n",
				"        # Split the data into training and testing sets\n",
				"        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
				"\n",
				"        # Initialize the Naive Bayes classifier\n",
				"        nb_classifier = GaussianNB()\n",
				"\n",
				"        # Fit the classifier to the training data\n",
				"        nb_classifier.fit(X_train, y_train)\n",
				"\n",
				"        # Make predictions on the testing set\n",
				"        y_pred = nb_classifier.predict(X_test)\n",
				"\n",
				"        # Evaluate the performance of the classifier\n",
				"        accuracy = accuracy_score(y_test, y_pred)\n",
				"        \n",
				"        # Check if the current accuracy is better than the best accuracy so far\n",
				"        if accuracy > best_accuracy:\n",
				"            best_accuracy = accuracy\n",
				"            best_test_size = test_size\n",
				"            best_random_state = random_state\n",
				"\n",
				"print(\"Best Accuracy:\", best_accuracy)\n",
				"print(\"Best Test Size:\", best_test_size)\n",
				"print(\"Best Random State:\", best_random_state)\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 31,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Best Hyperparameters: {'var_smoothing': 1e-09}\n",
						"Accuracy: 0.7947548460661346\n",
						"Classification Report:\n",
						"              precision    recall  f1-score   support\n",
						"\n",
						"           1       0.99      0.99      0.99       165\n",
						"           2       0.97      0.99      0.98       189\n",
						"           3       0.47      0.95      0.62       152\n",
						"           4       0.90      0.10      0.18       188\n",
						"           5       0.97      1.00      0.98       183\n",
						"\n",
						"    accuracy                           0.79       877\n",
						"   macro avg       0.86      0.81      0.75       877\n",
						"weighted avg       0.87      0.79      0.75       877\n",
						"\n"
					]
				}
			],
			"source": [
				"import pandas as pd\n",
				"from sklearn.model_selection import train_test_split, GridSearchCV\n",
				"from sklearn.naive_bayes import GaussianNB\n",
				"from sklearn.metrics import accuracy_score, classification_report\n",
				"\n",
				"# Load the data\n",
				"data = pd.read_csv('combined_metrics.csv')\n",
				"\n",
				"# Drop rows with missing values\n",
				"data.dropna(inplace=True)\n",
				"\n",
				"# Split the data into features (X) and target variable (y)\n",
				"X = data[::-1]\n",
				"y = data['category']\n",
				"\n",
				"# Split the data into training and testing sets\n",
				"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=176)\n",
				"\n",
				"# Initialize the Naive Bayes classifier\n",
				"nb_classifier = GaussianNB()\n",
				"\n",
				"# Define the hyperparameters grid to search\n",
				"param_grid = {\n",
				"    'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5]\n",
				"}\n",
				"\n",
				"# Initialize GridSearchCV\n",
				"grid_search = GridSearchCV(estimator=nb_classifier, param_grid=param_grid, cv=10, scoring='accuracy')\n",
				"\n",
				"# Perform GridSearchCV\n",
				"grid_search.fit(X_train, y_train)\n",
				"\n",
				"# Get the best hyperparameters\n",
				"best_params = grid_search.best_params_\n",
				"print(\"Best Hyperparameters:\", best_params)\n",
				"\n",
				"# Make predictions on the testing set using the best model\n",
				"best_model = grid_search.best_estimator_\n",
				"y_pred = best_model.predict(X_test)\n",
				"\n",
				"# Evaluate the performance of the best model\n",
				"accuracy = accuracy_score(y_test, y_pred)\n",
				"print(\"Accuracy:\", accuracy)\n",
				"\n",
				"# Generate a classification report for the best model\n",
				"print(\"Classification Report:\")\n",
				"print(classification_report(y_test, y_pred))\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 30,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Best Hyperparameters: {'var_smoothing': 1e-09}\n",
						"Accuracy: 0.7947548460661346\n",
						"Classification Report:\n",
						"              precision    recall  f1-score   support\n",
						"\n",
						"           1       0.99      0.99      0.99       165\n",
						"           2       0.97      0.99      0.98       189\n",
						"           3       0.47      0.95      0.62       152\n",
						"           4       0.90      0.10      0.18       188\n",
						"           5       0.97      1.00      0.98       183\n",
						"\n",
						"    accuracy                           0.79       877\n",
						"   macro avg       0.86      0.81      0.75       877\n",
						"weighted avg       0.87      0.79      0.75       877\n",
						"\n"
					]
				}
			],
			"source": [
				"import pandas as pd\n",
				"from sklearn.model_selection import train_test_split, GridSearchCV\n",
				"from sklearn.naive_bayes import GaussianNB\n",
				"from sklearn.metrics import accuracy_score, classification_report\n",
				"\n",
				"# Load the data\n",
				"data = pd.read_csv('combined_metrics.csv')\n",
				"\n",
				"# Drop rows with missing values\n",
				"data.dropna(inplace=True)\n",
				"\n",
				"# Split the data into features (X) and target variable (y)\n",
				"X = data[::-1]\n",
				"y = data['category']\n",
				"\n",
				"# Split the data into training and testing sets\n",
				"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=176)\n",
				"\n",
				"# Initialize the Naive Bayes classifier\n",
				"nb_classifier = GaussianNB()\n",
				"\n",
				"# Define the hyperparameters grid to search\n",
				"param_grid = {\n",
				"    'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5]\n",
				"}\n",
				"\n",
				"# Initialize GridSearchCV\n",
				"grid_search = GridSearchCV(estimator=nb_classifier, param_grid=param_grid, cv=10, scoring='accuracy')\n",
				"\n",
				"# Perform GridSearchCV\n",
				"grid_search.fit(X_train, y_train)\n",
				"\n",
				"# Get the best hyperparameters\n",
				"best_params = grid_search.best_params_\n",
				"print(\"Best Hyperparameters:\", best_params)\n",
				"\n",
				"# Make predictions on the testing set using the best model\n",
				"best_model = grid_search.best_estimator_\n",
				"y_pred = best_model.predict(X_test)\n",
				"\n",
				"# Evaluate the performance of the best model\n",
				"accuracy = accuracy_score(y_test, y_pred)\n",
				"print(\"Accuracy:\", accuracy)\n",
				"\n",
				"# Generate a classification report for the best model\n",
				"print(\"Classification Report:\")\n",
				"print(classification_report(y_test, y_pred))\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 38,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Best Hyperparameters: {'var_smoothing': 1e-09}\n",
						"Accuracy: 0.9840546697038725\n",
						"Classification Report:\n",
						"              precision    recall  f1-score   support\n",
						"\n",
						"           1       0.99      0.99      0.99        85\n",
						"           2       1.00      0.99      0.99        94\n",
						"           3       1.00      0.95      0.97        81\n",
						"           4       0.95      0.99      0.97        94\n",
						"           5       0.99      1.00      0.99        85\n",
						"\n",
						"    accuracy                           0.98       439\n",
						"   macro avg       0.99      0.98      0.98       439\n",
						"weighted avg       0.98      0.98      0.98       439\n",
						"\n"
					]
				}
			],
			"source": [
				"import pandas as pd\n",
				"from sklearn.model_selection import train_test_split, GridSearchCV\n",
				"from sklearn.naive_bayes import GaussianNB\n",
				"from sklearn.metrics import accuracy_score, classification_report\n",
				"\n",
				"# Load the data\n",
				"data = pd.read_csv('combined_metrics.csv')\n",
				"\n",
				"# Drop rows with missing values\n",
				"data.dropna(inplace=True)\n",
				"\n",
				"# Split the data into features (X) and target variable (y)\n",
				"X = data[::-1]\n",
				"y = data['category']\n",
				"\n",
				"# Split the data into training and testing sets\n",
				"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=121)\n",
				"\n",
				"# Initialize the Naive Bayes classifier\n",
				"nb_classifier = GaussianNB()\n",
				"\n",
				"# Define the hyperparameters grid to search\n",
				"param_grid = {\n",
				"    'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5]\n",
				"}\n",
				"\n",
				"# Initialize GridSearchCV\n",
				"grid_search = GridSearchCV(estimator=nb_classifier, param_grid=param_grid, cv=10, scoring='accuracy')\n",
				"\n",
				"# Perform GridSearchCV\n",
				"grid_search.fit(X_train, y_train)\n",
				"\n",
				"# Get the best hyperparameters\n",
				"best_params = grid_search.best_params_\n",
				"print(\"Best Hyperparameters:\", best_params)\n",
				"\n",
				"# Make predictions on the testing set using the best model\n",
				"best_model = grid_search.best_estimator_\n",
				"y_pred = best_model.predict(X_test)\n",
				"\n",
				"# Evaluate the performance of the best model\n",
				"accuracy = accuracy_score(y_test, y_pred)\n",
				"print(\"Accuracy:\", accuracy)\n",
				"\n",
				"# Generate a classification report for the best model\n",
				"print(\"Classification Report:\")\n",
				"print(classification_report(y_test, y_pred))\n",
				"\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 41,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Accuracy: 0.9840546697038725\n",
						"Classification Report:\n",
						"              precision    recall  f1-score   support\n",
						"\n",
						"           1       0.99      0.99      0.99        85\n",
						"           2       1.00      0.99      0.99        94\n",
						"           3       1.00      0.95      0.97        81\n",
						"           4       0.95      0.99      0.97        94\n",
						"           5       0.99      1.00      0.99        85\n",
						"\n",
						"    accuracy                           0.98       439\n",
						"   macro avg       0.99      0.98      0.98       439\n",
						"weighted avg       0.98      0.98      0.98       439\n",
						"\n"
					]
				}
			],
			"source": [
				"import pandas as pd\n",
				"from sklearn.model_selection import train_test_split\n",
				"from sklearn.naive_bayes import GaussianNB\n",
				"from sklearn.metrics import accuracy_score, classification_report\n",
				"\n",
				"# Load the data\n",
				"data = pd.read_csv('combined_metrics.csv')\n",
				"\n",
				"# Drop rows with missing values\n",
				"data.dropna(inplace=True)\n",
				"\n",
				"# Split the data into features (X) and target variable (y)\n",
				"X = data[::-1]\n",
				"y = data['category']\n",
				"\n",
				"# Split the data into training and testing sets\n",
				"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=121)\n",
				"\n",
				"# Initialize the Naive Bayes classifier\n",
				"nb_classifier = GaussianNB()\n",
				"\n",
				"# Train the classifier on the training data\n",
				"nb_classifier.fit(X_train, y_train)\n",
				"\n",
				"# Make predictions on the testing set\n",
				"y_pred = nb_classifier.predict(X_test)\n",
				"\n",
				"# Evaluate the performance of the classifier\n",
				"accuracy = accuracy_score(y_test, y_pred)\n",
				"print(\"Accuracy:\", accuracy)\n",
				"\n",
				"# Generate a classification report for the classifier\n",
				"print(\"Classification Report:\")\n",
				"print(classification_report(y_test, y_pred))\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 45,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Training Accuracy: 0.9591784989858012\n",
						"Test Accuracy: 0.9840546697038725\n",
						"Classification Report:\n",
						"              precision    recall  f1-score   support\n",
						"\n",
						"           1       0.99      0.99      0.99        85\n",
						"           2       1.00      0.99      0.99        94\n",
						"           3       1.00      0.95      0.97        81\n",
						"           4       0.95      0.99      0.97        94\n",
						"           5       0.99      1.00      0.99        85\n",
						"\n",
						"    accuracy                           0.98       439\n",
						"   macro avg       0.99      0.98      0.98       439\n",
						"weighted avg       0.98      0.98      0.98       439\n",
						"\n"
					]
				}
			],
			"source": [
				"import pandas as pd\n",
				"import matplotlib.pyplot as plt\n",
				"from sklearn.model_selection import train_test_split\n",
				"from sklearn.naive_bayes import GaussianNB\n",
				"from sklearn.metrics import accuracy_score, classification_report\n",
				"\n",
				"# Load the data\n",
				"data = pd.read_csv('combined_metrics.csv')\n",
				"\n",
				"# Drop rows with missing values\n",
				"data.dropna(inplace=True)\n",
				"\n",
				"# Split the data into features (X) and target variable (y)\n",
				"X = data[::-1]\n",
				"y = data['category']\n",
				"\n",
				"# Split the data into training and testing sets\n",
				"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=121)\n",
				"\n",
				"# Initialize the Naive Bayes classifier\n",
				"nb_classifier = GaussianNB()\n",
				"\n",
				"# Train the classifier on the training data\n",
				"nb_classifier.fit(X_train, y_train)\n",
				"\n",
				"# Compute training accuracy\n",
				"y_train_pred = nb_classifier.predict(X_train)\n",
				"train_accuracy = accuracy_score(y_train, y_train_pred)\n",
				"print(\"Training Accuracy:\", train_accuracy)\n",
				"\n",
				"# Make predictions on the testing set\n",
				"y_pred = nb_classifier.predict(X_test)\n",
				"\n",
				"# Evaluate the performance of the classifier\n",
				"test_accuracy = accuracy_score(y_test, y_pred)\n",
				"print(\"Test Accuracy:\", test_accuracy)\n",
				"\n",
				"# Generate a classification report for the classifier\n",
				"print(\"Classification Report:\")\n",
				"print(classification_report(y_test, y_pred))\n",
				"\n",
				"\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 51,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Cross-Validation Scores: [0.6856492  0.98861048 1.         1.         1.         1.\n",
						" 1.         1.         1.         0.84931507]\n",
						"Average Cross-Validation Score: 0.9523574749586545\n",
						"Training Accuracy: 0.9591784989858012\n",
						"Testing Accuracy: 0.9840546697038725\n",
						"Classification Report:\n",
						"              precision    recall  f1-score   support\n",
						"\n",
						"           1       0.99      0.99      0.99        85\n",
						"           2       1.00      0.99      0.99        94\n",
						"           3       1.00      0.95      0.97        81\n",
						"           4       0.95      0.99      0.97        94\n",
						"           5       0.99      1.00      0.99        85\n",
						"\n",
						"    accuracy                           0.98       439\n",
						"   macro avg       0.99      0.98      0.98       439\n",
						"weighted avg       0.98      0.98      0.98       439\n",
						"\n"
					]
				}
			],
			"source": [
				"import pandas as pd\n",
				"import matplotlib.pyplot as plt\n",
				"from sklearn.model_selection import cross_val_score, train_test_split\n",
				"from sklearn.naive_bayes import GaussianNB\n",
				"from sklearn.metrics import accuracy_score, classification_report\n",
				"\n",
				"# Load the data\n",
				"data = pd.read_csv('combined_metrics.csv')\n",
				"\n",
				"# Drop rows with missing values\n",
				"data.dropna(inplace=True)\n",
				"\n",
				"# Split the data into features (X) and target variable (y)\n",
				"X = data[::-1]\n",
				"y = data['category']\n",
				"\n",
				"# Split the data into training and testing sets\n",
				"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=121)\n",
				"\n",
				"# Initialize the Naive Bayes classifier\n",
				"nb_classifier = GaussianNB()\n",
				"\n",
				"# Perform k-fold cross-validation\n",
				"k = 10  # number of folds\n",
				"cv_scores = cross_val_score(nb_classifier, X, y, cv=k)\n",
				"\n",
				"# Print the cross-validation sc\n",
				"print(\"Cross-Validation Scores:\", cv_scores)\n",
				"\n",
				"# Compute the average cross-validation score\n",
				"avg_cv_score = cv_scores.mean()\n",
				"print(\"Average Cross-Validation Score:\", avg_cv_score)\n",
				"\n",
				"# Train the classifier on the entire training data\n",
				"nb_classifier.fit(X_train, y_train)\n",
				"\n",
				"# Compute training accuracy\n",
				"train_accuracy = accuracy_score(y_train, nb_classifier.predict(X_train))\n",
				"print(\"Training Accuracy:\", train_accuracy)\n",
				"\n",
				"# Make predictions on the testing set\n",
				"y_pred = nb_classifier.predict(X_test)\n",
				"\n",
				"# Compute testing accuracy\n",
				"test_accuracy = accuracy_score(y_test, y_pred)\n",
				"print(\"Testing Accuracy:\", test_accuracy)\n",
				"\n",
				"# Generate a classification report for the classifier\n",
				"print(\"Classification Report:\")\n",
				"print(classification_report(y_test, y_pred))\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Best Accuracy: 1.0\n",
						"Best Test Size: 0.1\n",
						"Best Random State: 43\n"
					]
				}
			],
			"source": [
				"import pandas as pd\n",
				"from sklearn.model_selection import train_test_split\n",
				"from sklearn.naive_bayes import GaussianNB\n",
				"from sklearn.metrics import accuracy_score, classification_report\n",
				"\n",
				"# Load the data\n",
				"data = pd.read_csv('Dataset/fft_combined_metrics.csv')\n",
				"\n",
				"# Drop rows with missing values\n",
				"data.dropna(inplace=True)\n",
				"\n",
				"# Split the data into features (X) and target variable (y)\n",
				"X = data[::-1]\n",
				"y = data['category']\n",
				"\n",
				"# Define the range of test sizes and random states to iterate over\n",
				"test_sizes = [0.1, 0.15, 0.2, 0.25, 0.3]\n",
				"random_states = list(range(42, 201))\n",
				"\n",
				"best_accuracy = 0\n",
				"best_test_size = 0\n",
				"best_random_state = 0\n",
				"\n",
				"for test_size in test_sizes:\n",
				"    for random_state in random_states:\n",
				"        # Split the data into training and testing sets\n",
				"        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
				"\n",
				"        # Initialize the Naive Bayes classifier\n",
				"        nb_classifier = GaussianNB()\n",
				"\n",
				"        # Fit the classifier to the training data\n",
				"        nb_classifier.fit(X_train, y_train)\n",
				"\n",
				"        # Make predictions on the testing set\n",
				"        y_pred = nb_classifier.predict(X_test)\n",
				"\n",
				"        # Evaluate the performance of the classifier\n",
				"        accuracy = accuracy_score(y_test, y_pred)\n",
				"        \n",
				"        # Check if the current accuracy is better than the best accuracy so far\n",
				"        if accuracy > best_accuracy:\n",
				"            best_accuracy = accuracy\n",
				"            best_test_size = test_size\n",
				"            best_random_state = random_state\n",
				"\n",
				"print(\"Best Accuracy:\", best_accuracy)\n",
				"print(\"Best Test Size:\", best_test_size)\n",
				"print(\"Best Random State:\", best_random_state)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 3,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Cross-Validation Scores: [0.77777778 1.         1.         1.         1.        ]\n",
						"Average Cross-Validation Score: 0.9555555555555555\n",
						"Training Accuracy: 0.9459459459459459\n",
						"Testing Accuracy: 1.0\n",
						"Classification Report:\n",
						"              precision    recall  f1-score   support\n",
						"\n",
						"           1       1.00      1.00      1.00         2\n",
						"           2       1.00      1.00      1.00         1\n",
						"           4       1.00      1.00      1.00         1\n",
						"           5       1.00      1.00      1.00         1\n",
						"\n",
						"    accuracy                           1.00         5\n",
						"   macro avg       1.00      1.00      1.00         5\n",
						"weighted avg       1.00      1.00      1.00         5\n",
						"\n"
					]
				}
			],
			"source": [
				"import pandas as pd\n",
				"import matplotlib.pyplot as plt\n",
				"from sklearn.model_selection import cross_val_score, train_test_split\n",
				"from sklearn.naive_bayes import GaussianNB\n",
				"from sklearn.metrics import accuracy_score, classification_report\n",
				"\n",
				"# Load the data\n",
				"data = pd.read_csv('Dataset/fft_combined_metrics.csv')\n",
				"\n",
				"# Drop rows with missing values\n",
				"data.dropna(inplace=True)\n",
				"\n",
				"# Split the data into features (X) and target variable (y)\n",
				"X = data[::-1]\n",
				"y = data['category']\n",
				"\n",
				"# Split the data into training and testing sets\n",
				"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=43)\n",
				"\n",
				"# Initialize the Naive Bayes classifier\n",
				"nb_classifier = GaussianNB()\n",
				"\n",
				"# Perform k-fold cross-validation\n",
				"k = 5 # number of folds\n",
				"cv_scores = cross_val_score(nb_classifier, X, y, cv=k)\n",
				"\n",
				"# Print the cross-validation sc\n",
				"print(\"Cross-Validation Scores:\", cv_scores)\n",
				"\n",
				"# Compute the average cross-validation score\n",
				"avg_cv_score = cv_scores.mean()\n",
				"print(\"Average Cross-Validation Score:\", avg_cv_score)\n",
				"\n",
				"# Train the classifier on the entire training data\n",
				"nb_classifier.fit(X_train, y_train)\n",
				"\n",
				"# Compute training accuracy\n",
				"train_accuracy = accuracy_score(y_train, nb_classifier.predict(X_train))\n",
				"print(\"Training Accuracy:\", train_accuracy)\n",
				"\n",
				"# Make predictions on the testing set\n",
				"y_pred = nb_classifier.predict(X_test)\n",
				"\n",
				"# Compute testing accuracy\n",
				"test_accuracy = accuracy_score(y_test, y_pred)\n",
				"print(\"Testing Accuracy:\", test_accuracy)\n",
				"\n",
				"# Generate a classification report for the classifier\n",
				"print(\"Classification Report:\")\n",
				"print(classification_report(y_test, y_pred))"
			]
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": "Python 3 (ipykernel)",
			"language": "python",
			"name": "python3"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "ipython",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "python",
			"nbconvert_exporter": "python",
			"pygments_lexer": "ipython3",
			"version": "3.11.4"
		}
	},
	"nbformat": 4,
	"nbformat_minor": 4
}
